# AI排名分析系统使用指南

## 概述

本系统用于追踪AI平台上的搜索排名，帮助优化广告投放策略。系统分为两个独立部分：

1. **Crawler（爬虫）** - 采集AI平台的排名数据
2. **Analyzer（分析器）** - 分析数据并生成报告

## 系统架构

```
jobs/
  <任务名>/
    metadata.json         # 任务元数据（包含关键词列表）
    runs/
      run_<时间戳>/
        results.csv       # 原始爬取结果
        statistics.json   # 统计数据（分析器生成）
        report.html       # HTML报告（分析器生成）
        report.txt        # 文本报告（分析器生成）
        crawler.log       # 爬虫日志
```

## 安装依赖

```bash
# 确保已安装 rich 库
uv add rich
```

## 使用方法

### 第一步：创建任务并爬取数据

#### 创建新任务

```bash
python crawler.py new 任务名 \
    --keywords "关键词1" "关键词2" "关键词3" \
    --target-product "我的产品名"
```

**示例：**
```bash
python crawler.py new 二奢回收广告 \
    --keywords "二手奢侈品上门回收" "上海二奢店哪家比较靠谱" "二奢上门回收" \
    --target-product "我的二奢回收平台"
```

**参数说明：**
- `任务名`: 唯一的任务标识符
- `--keywords`: 要查询的关键词列表（空格分隔）
- `--target-product`: （可选）你的产品名称，用于跟踪排名（支持模糊匹配）
- `--config`: （可选）配置文件路径，默认 `config.json`

#### 恢复中断的任务

如果爬取过程被中断（Ctrl+C 或崩溃），可以继续：

```bash
python crawler.py resume 任务名
```

系统会自动跳过已处理的关键词，从中断处继续。

#### 重新运行现有任务

使用相同的关键词进行新一轮爬取（例如一周后检查排名变化）：

```bash
python crawler.py rerun 任务名
```

这会创建新的运行记录，不影响之前的数据。

### 第二步：分析数据

爬取完成后，使用分析器生成统计报告：

```bash
# 分析最新一次运行
python analyzer.py 任务名

# 分析特定运行
python analyzer.py 任务名 --run-id run_20250125_100000

# 只生成JSON
python analyzer.py 任务名 --export json

# 只生成HTML
python analyzer.py 任务名 --export html
```

## 爬取过程

运行 crawler 时会看到实时进度：

```
⠋ Crawling keywords for job '二奢回收广告' ━━━━━━━━━━━━━━ 5/10 50% • 00:01:15 • 00:01:15

当前: 上海二奢上门回收
成功: 4 | 失败: 1
```

特点：
- ✓ 实时进度条显示
- ✓ 成功/失败计数
- ✓ 预计剩余时间
- ✓ 框架日志已抑制（仅显示WARNING级别）
- ✓ 详细日志记录到 `crawler.log`

## 分析报告

### 报告包含的统计信息

1. **来源网站统计**
   - 排名第一的来源网站及占比
   - 前二名来源网站占比
   - 前三名来源网站占比
   - 所有来源网站的出现频率

2. **产品/平台统计**
   - 排名第一的产品及占比
   - 前二名产品占比
   - 前三名产品占比
   - 所有产品的出现频率

3. **目标产品表现**（如果指定了 target-product）
   - 出现次数和占比
   - 在各排名位置的次数
   - 平均排名
   - 表现最好/最差的关键词

### 报告格式

#### 1. 文本报告 (report.txt)

纯文本格式，适合快速查看：

```
====================================================
AI排名分析报告：二奢回收广告
====================================================
生成时间：2025-12-25T10:30:00
运行ID：run_20251225_100000

总览
----------------------------------------------------
总关键词数：       10
成功查询数：       9
失败查询数：       1
成功率：           90.0%

排名第一的来源网站
----------------------------------------------------
小红书 (xiaohongshu.com)      33.3% (3次)
知乎 (zhihu.com)               22.2% (2次)
...
```

#### 2. HTML报告 (report.html)

交互式网页报告，包含：
- 总览仪表盘
- 饼图：排名第一的来源分布
- 柱状图：热门产品分布
- 详细表格

用浏览器打开即可查看。

#### 3. JSON数据 (statistics.json)

结构化数据，方便程序化处理或后续分析。

## 关键特性

### 1. 崩溃恢复

爬虫将每个关键词的结果立即写入CSV，确保：
- 程序崩溃后可以恢复
- 不会丢失已采集的数据
- 使用 `resume` 命令继续

### 2. 模糊匹配目标产品

目标产品使用子串匹配（不区分大小写）：
- `"KMS"` 可以匹配 `"KiM Service"`
- `"回收"` 可以匹配 `"上海二手回收平台"`

这样可以捕获产品的各种提及方式。

### 3. 来源展示

来源同时显示网站名和域名：
- `"小红书 (xiaohongshu.com)"`
- `"知乎 (zhihu.com)"`

### 4. 中文报告

所有报告使用中文：
- 标题、标签、说明均为中文
- 适合中文用户直接使用

### 5. 多次运行支持

同一任务可以运行多次：
- 每次运行创建独立的文件夹
- 便于对比不同时期的排名变化
- 未来可扩展时间序列分析

## 完整工作流示例

```bash
# 1. 创建任务并开始爬取
python crawler.py new 健身教练广告_202501 \
    --keywords "上海私人健身教练" "浦东女健身教练上门" "健身私教推荐" \
    --target-product "FOR U健身私教馆"

# 爬取过程中显示进度...
# 结果保存到: jobs/健身教练广告_202501/runs/run_20250125_100000/

# 2. 分析结果
python analyzer.py 健身教练广告_202501

# 分析完成！
# 报告已保存至: jobs/健身教练广告_202501/runs/run_20250125_100000/
#   - statistics.json
#   - report.html
#   - report.txt

# 3. 查看报告
# 在浏览器中打开 report.html

# 4. 一周后重新运行，检查广告效果
python crawler.py rerun 健身教练广告_202501
# 结果保存到: jobs/健身教练广告_202501/runs/run_20250201_100000/

python analyzer.py 健身教练广告_202501
# 分析最新一次运行

# 5. （未来）对比两次运行的排名变化
python trend_analyzer.py 健身教练广告_202501
# 显示排名趋势和变化
```

## 注意事项

1. **关键词数量**: 考虑到API速率限制，建议每个任务不超过50个关键词

2. **运行时间**:
   - 默认配置：4次请求/60秒，最小间隔15秒
   - 10个关键词约需 3-5 分钟
   - 50个关键词约需 15-25 分钟

3. **数据存储**:
   - CSV文件包含完整内容，可能较大
   - 建议定期清理旧的运行数据

4. **目标产品**:
   - 使用模糊匹配，尽量使用简短的核心词
   - 例如用 `"KMS"` 而不是 `"KMS健身私教服务平台"`

## 故障排除

### 问题：任务已存在
```
错误：Job 'xxx' already exists
```
**解决**：使用 `rerun` 命令或选择不同的任务名

### 问题：无法恢复
```
错误：Job 'xxx' already completed. Use 'rerun' to run again.
```
**解决**：任务已完成，使用 `rerun` 创建新运行

### 问题：没有结果文件
```
错误：Results file not found
```
**解决**：确保先运行 crawler，再运行 analyzer

### 问题：所有查询都失败
**可能原因**：
- API配置错误
- 网络问题
- 账号被限制

**检查**：
- 查看 `crawler.log` 获取详细错误
- 验证 `config.json` 配置
- 检查账号状态

## 未来功能（计划中）

1. **时间序列分析** (`trend_analyzer.py`)
   - 对比多次运行的数据
   - 追踪排名变化趋势
   - 识别竞争对手变化

2. **任务对比**
   - 并排对比两个不同任务
   - A/B测试关键词效果

3. **导出功能增强**
   - 导出到Google Sheets
   - 与分析平台集成

4. **高级可视化**
   - 竞争对手重叠矩阵
   - 关键词难度评分
   - 域名权威度追踪
